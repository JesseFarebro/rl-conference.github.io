[{"content":"<h1>The why behind RLC</h1>\n\n<p>We\u2019re so excited to launch the first version of the RLC, the new archival conference focused exclusively on reinforcement learning. There\u2019s been a lot of attention, and we figured this would be a good moment to explain why we think now is the right moment to launch a new RL conference and talk a bit about what makes RLC different from other ML conferences. Besides the obvious, that we\u2019re RL-focused, there\u2019s a whole host of things that we\u2019re trying to make this a uniquely worthwhile conference to submit to and attend.</p>\n\n<h2>Why a new archival RL conference?</h2>\n\n<p>This is the question we get the most. It\u2019s a few things that make the RL community, and RL papers, somewhat distinct and that we think benefit from a conference being archival:\n- RL is not a monolithic topic; it\u2019s a lot of subgroups roughly pursuing a similar topic. Having an archival RL conference lets us have sessions organized more appropriately to subgroups in the RL community.\n- It is beneficial to RL practitioners and researchers to have a dedicated venue to find top-quality work with top quality reviewing that follows high standards defined by the RL community.\n- In the longer-term, it will help the RL community develop those standards for reproducibility, best practices, etc. that are necessary to address challenges that are more important to RL.</p>\n\n<p>Finally, a yearly archival RL conference provides an opportunity to create a coherent RL community. The  RL community is gigantic and even though we all work on so many different problems, there are a lot of unifying themes in the work and concepts we can learn from each other. Researchers lucky enough to attend prior RLDM events have been overwhelmingly enthusiastic about it, which suggests that there\u2019s a real need for a yearly event that brings the community together outside of the general ML conferences. This community building is also important because RL research is growing in size and complexity, which is resulting in larger papers and more tools needed to support research efforts.</p>\n\n<h2>Why should you submit?</h2>\n\n<p>The conference is new, yet we are already getting significant interest for submission details and where to submit work. The pragmatic case for submission is this: you submit to conferences to (1) make folks aware of your work and get feedback on it and (2) you attend conferences to have interesting conversations and learn about the state-of-the-art. We believe that there\u2019s no better way to draw attention to an RL paper than submitting to RLC. In this first iteration, submitting your paper to RLC and receiving a spotlight or poster is a way to get it in front of a really large fraction of the RL community. These important connections are much more difficult at larger more general conferences. Due to their size, this will not occur except for a few papers when submitting it to a 15000 person conference like NeurIPS. The larger a conference is, the more power-law effects come into play and so a lot of focus gets placed on a smaller number of papers. </p>\n\n<p>There are a few more reasons we\u2019d like to highlight. Our review process (discussed below) places an extremely high technical bar for the inclusion of a paper. As such, we think having a paper accepted to RLC will constitute a mark of paper quality.  </p>\n\n<h2>What we\u2019re doing differently</h2>\n\n<p>Because we\u2019re a new conference, we can take some exciting risks and try to fix long-standing issues we\u2019ve seen in the ML community. The key change is creating a technically rigorous, but quite different and efficient review process that should set a high technical bar and help provide more useful reviews!</p>\n\n<h3>Review process</h3>\n\n<p>Everyone understands that the review process in ML is becoming challenging with increasingly overburdened reviewers starting to submit slipshod reviews. Rather than trying to fix the process with another change atop things, the RLC program chairs (Martha White, Adam White, and Feyral Behbahani) have come up with a new procedure that pares things down:</p>\n\n<ul>\n<li>Rather than asking reviewers to judge the novelty or impact of an approach, which we think is something the research community will do on its own through citations, we\u2019re just asking reviewers to judge the technical correctness of the work. This simplifies the job of reviewing and hopefully eases the review burden. A lower review burden means we can ask technical reviewers to provide even more thorough reviews.</li>\n<li>Rather than ensure that you receive many reviews, we\u2019re focusing on a smaller number of high-quality reviews. Reviews will come from more senior PhD students focused on technical correctness paired with a senior reviewer who will double-check the review and provide a more high-level perspective on the relationship of the paper to the field. We are also empowering the senior to throw out low quality technical reviews that simply add noise to the process.</li>\n<li>As to the above, we are setting a high technical bar for a paper being correct. More information on this will come out soon.</li>\n</ul>\n\n<p>We hope that providing good feedback makes the RLC submission process more informative and useful. Whether your paper gets in or not, you\u2019ll receive detailed feedback from experts that allows you to improve the quality of your paper (just in time for NeurIPS if your paper doesn\u2019t get in!). As a reviewer, you actually get to learn how to review from the senior reviewer. For much more detail on the review process there\u2019ll be another blog post coming soon discussing all this in more detail and explaining how we came to this setup.</p>\n\n<h2>Some questions that come up frequently</h2>\n\n<h3>What about RLDM?</h3>\n\n<p>We love RLDM and think it\u2019s great. At the same time, we think it\u2019s important to have something archival for the reasons outlined above.</p>\n\n<h3>What about EWRL?</h3>\n\n<p>We think EWRL is great too and are actively exploring ways to bring RLC and EWRL together. At the same time, we think it\u2019s important to have a venue that is both archival and free to move from continent to continent.</p>\n\n<h3>Are you worried this will split up RL from the ML community?</h3>\n\n<p>There are over 10,000 RL papers written every year. More than enough of these will go to other ML conferences such that RL still remains a major part of those conferences while RLC can still provide a focused spotlight on good RL papers.</p>\n","file_path":"/blogs/why_rlc.md","title":"What's exciting about RLC?"},{"content":"<h1>On RLC\u2019s Outstanding Paper Awards</h1>\n\n<p>At RLC the \u201cOutstanding Paper Award\u201d will be different from what is traditionally done in machine learning conferences. We will not award papers for being the overall \u201cbest\u201d papers in a conference; instead we will award papers for making significant contributions to specific aspects of research. We believe such an approach will be more inclusive\u2013it will celebrate the diverse types of scientific contribution one can make in the field, and it will provide more equal opportunities for different types of papers to be awarded. The idea is to award papers for excelling in what they aimto accomplish.</p>\n\n<p>It is commonly agreed that best paper awards are not necessarily a good predictor of impact in the future. We designed this award system with this in mind. Aligned with the RLC reviewing guidelines, this system tries not to award papers for the popularity of the topic they investigate, nor for their perceived novelty or potential future impact. </p>\n\n<p>We are also hoping that this process will decouple scores and the likelihood of an award. Currently, in many systems, a single non-committal review can drastically reduce the chances of a paper receiving an award.</p>\n\n<p>This system was designed to recognize and promote the diversity in our field. Papers that make meaningful contributions to real-world problems can be awarded in the same way that a purely theoretical paper can. Papers that close a gap in our understanding, or that report interesting negative results can also be recognized, or those that introduce a completely new perspective to the field. Finally, we also believe that the computational resources one has access to also should not change the likelihood of a paper receiving an award; thus there is a category for excelling in doing empirical research frugally. </p>\n\n<p>There will be six award categories, they are the following (in alphabetical order):</p>\n\n<ul>\n<li>Outstanding Paper Award on Applications of Reinforcement Learning</li>\n<li>Outstanding Paper Award on Empirical Reinforcement Learning Research </li>\n<li>Outstanding Paper Award on Empirical Resourcefulness in Reinforcement Learning</li>\n<li>Outstanding Paper Award on Pioneering Vision in Reinforcement Learning</li>\n<li>Outstanding Paper Award on Scientific Understanding in Reinforcement Learning</li>\n<li>Outstanding Paper Award on the Theory of Reinforcement Learning</li>\n</ul>\n\n<p>A more detailed description of each category is available at the end of this post. Importantly, <em>no award is more prestigious than the other.</em></p>\n\n<h2>And how is this going to work?</h2>\n\n<p>In the review form, the technical reviewer and the senior reviewer will have to answer six yes/no questions in the form \u201cShould this paper be nominated for the Outstanding Paper Award on X?\u201d. These are not exclusive, so one paper can be nominated for more than one award. If the paper is nominated for any award, the nominator will be asked to write an additional paragraph justifying the nomination. </p>\n\n<p>As discussed above, at RLC, the overall scores a paper receives will not necessarily determine whether the paper will receive an award or not. A paper might be accepted with a \u201cWeak accept\u201d but it may have excelled in a specific aspect captured by an award. We will encourage reviewers to nominate such papers. This approach is an attempt to decorrelate the noise from the review process from the award itself. As a concrete example, a paper might be accepted with a \u201cWeak accept\u201d because the reviewers recognize that the paper provides important theoretical results that tackles a major theoretical question in reinforcement learning, but these new results do not necessarily lead to major performance improvements (whether such a paper should receive a Strong Accept is beyond the scope of this post, we are simply acknowledging the noisiness of the process here). Such a paper should probably be nominated for the <em>Outstanding Paper Award on the Theory of Reinforcement Learning</em>. </p>\n\n<p>Importantly, more than one paper can potentially receive the same award in a given year, and there might be years in which an award is not given. </p>\n\n<p>We hope you find this interesting!</p>\n\n<p><em>RLC Awards co-chairs</em></p>\n\n<p><em>Roberta Raileanu &amp; Marlos C. Machado</em></p>\n\n<h2>Description of Award Categories (Alphabetical Order)</h2>\n\n<h3>Outstanding Paper Award on Applications of Reinforcement Learning</h3>\n\n<p><em>This award aims to acknowledge papers that demonstrate substantial progress on the application of reinforcement learning to complex, real-world problems. This award seeks to highlight groundbreaking work formulating real-world problems using the reinforcement learning framework, introducing a new application domain or challenge to reinforcement learning, or developing reinforcement learning methods that make significant progress on practical scenarios.  The papers should display a notable level of practical utility and uphold a high standard of scientific rigor.</em></p>\n\n<h3>Outstanding Paper Award on Empirical Reinforcement Learning Research</h3>\n\n<p>This award recognizes papers that make significant contributions to the empirical aspects of reinforcement learning research. Examples include addressing fundamental practical challenges in reinforcement learning, introducing new empirical practices, methodologies, benchmarks, evaluation metrics, and visualization techniques, and providing tools and frameworks that will further enable empirical research. These papers should show a high standard of practical relevance and experimental rigor.</p>\n\n<h3>Outstanding Paper Award on Empirical Resourcefulness in Reinforcement Learning</h3>\n\n<p><em>This award honors papers that demonstrate resourcefulness in empirical research. These are papers that overcome the high computational cost of empirical research in reinforcement learning in ingenious ways, promoting more frugal empirical research. Examples include showcasing original, cost-effective methodologies, and resource-efficient experimental designs. The papers should embody high standards of creativity and practicality without sacrificing experimental rigor.</em></p>\n\n<h3>Outstanding Paper Award on Pioneering Vision in Reinforcement Learning</h3>\n\n<p><em>This award highlights papers that stand out with their forward-thinking vision and blue-sky ideas in the field of reinforcement learning. The papers awarded in this category will present groundbreaking, visionary ideas, theories, or techniques in reinforcement learning, potentially reshaping current perspectives or opening new avenues for research and applications. The papers must demonstrate originality, creativity, and the potential to inspire transformative advancements in reinforcement learning.</em></p>\n\n<h3>Outstanding Paper Award on Scientific Understanding in Reinforcement Learning</h3>\n\n<p><em>This award celebrates papers that significantly advance scientific understanding in the domain of reinforcement learning. It encourages the development of well-founded, clear understanding of the behavior of existing algorithms or the nuances of different problem formulations or different environments. Awarded papers will fill gaps in our understanding of the field; they will bring clarity to unexplored aspects of existing algorithms, they will provide evidence to dispute common assumptions, or they will better justify common practices in the field. They should also demonstrate excellence in scientific rigor and clarity of exposition, with very well-defined claims.</em></p>\n\n<h3>Outstanding Paper Award on the Theory of Reinforcement Learning</h3>\n\n<p><em>This award acknowledges papers that provide exceptional theoretical contributions to the field of reinforcement learning. Examples include theoretical unifications, new theoretical frameworks or formalisms, mathematical models, results, and theoretical insights into existing RL practices. The papers must exhibit a high level of technical proficiency and innovation.</em></p>\n","file_path":"/blogs/awards_process.md","title":"On RLC\u2019s Outstanding Paper Awards"}]
